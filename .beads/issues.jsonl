{"id":"ai-pipelines-07k","title":"Experiment: Single-step 280-char with faithfulness self-check","description":"Hypothesis: Based on exp1 (best 0.9245). Two issues: (1) 200-char limit too tight for no_silver_bullet - model can't cover 20 QA topics in 10 args at 200 chars each; (2) feeding faithfulness dropped (4 unsupported claims). Fix: relax to 280-char per main_argument (enough room for all QA topics while still concise), add 'verify against extracted points' self-check in template. Expected: no_silver_bullet qa 0.85→0.95+, feeding faithfulness 0.875→0.93+, avg 0.93+","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T22:48:06.162628532-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T23:08:19.224844663-07:00","closed_at":"2026-02-22T23:08:19.224844663-07:00","close_reason":"failed: CRASHED - systematic_review data-table chunks cause haiku to omit section_topic field (required property). Same crash as exp3/exp6. Root fix needed: make section_topic optional in schema."}
{"id":"ai-pipelines-086","title":"Experiment: 12-16 arguments at 200-char (more topic coverage)","description":"Hypothesis: From exp9 (best 0.9299). QA is 0.818-0.85 (3-4 questions missed per paper). The 200-char limit is near-optimal (exp10 showed 250-char hurts). BUT we can cover MORE topics by increasing argument count from 8-12 to 12-16 items at the same 200-char limit. Each extra argument adds 200 chars for one new distinct QA topic. Expected: QA improves 0.85→0.90+, minor conciseness decrease. Also increase key_evidence to 8-12 items to capture more specific entities.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-23T01:22:53.537698745-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-23T01:46:29.865037745-07:00","closed_at":"2026-02-23T01:46:29.865037745-07:00","close_reason":"CRASHED: XML prompt injection. systematic_review data table chunks → haiku contaminates extracted points with XML tool-use tags → sonnet synthesis echoes XML format for output. Pipeline crash. Would have been excellent (16 detailed ρc/k/n stats) if it had validated."}
{"id":"ai-pipelines-22p","title":"Experiment: Exp1 exact with section_topic optional crash fix","description":"Hypothesis: Experiments 3,6,7 all crashed due to section_topic being required in extraction schema. Systematic_review data-table chunks cause haiku to omit section_topic. Fix: make section_topic NOT required. Keep everything else from exp1 exactly (200-char limits, named entity extraction, single-step synthesis). Expected: no crashes, results similar to exp1 (avg ~0.9245) with potential slight variation. This is the safest possible improvement - purely defensive.","status":"closed","priority":1,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T23:58:32.649968926-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-23T00:39:52.598773075-07:00","closed_at":"2026-02-23T00:39:52.598773075-07:00","close_reason":"improved avg from 0.9254 to 0.9299. feeding improved 0.8882→0.9128 (qa 0.85, faithfulness 0.9583). No crashes. section_topic optional fix is critical."}
{"id":"ai-pipelines-2t7","title":"Experiment: Named entity diversity rule for feeding QA","description":"Hypothesis: From exp12 (best 0.9400). Feeding qa dropped 0.85→0.80. The 12-16 argument instruction might be generating arguments that focus on distinct formal topics but miss specific named entities (tools, people, products) that are the QA targets for essay-style papers. Fix: add explicit coverage instruction 'For each category of named entity (person, tool/product, organization, named concept/effect), at least one argument or evidence item must explicitly name it'. This directly targets feeding QA improvement without changing other behavior.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-23T02:33:13.281704586-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-23T03:22:14.912987416-07:00","closed_at":"2026-02-23T03:22:14.912987416-07:00","close_reason":"failed: entity diversity rule hurt no_silver_bullet QA (1.0→0.85). Faithfulness improved for other papers but overall avg 0.9400→0.9335 regression."}
{"id":"ai-pipelines-2z7","title":"Experiment: 250-char limits + allow up to 14 arguments","description":"Hypothesis: From exp9 (best 0.9299). QA still limited: systematic_review 0.85 (17/20), feeding 0.85 (17/20), no_silver_bullet 0.818 (18/22). Two adjustments: (1) relax char limits from 200→250 chars per main_argument (25% more room per item without the radical removal of all limits that hurt exp2); (2) increase max arguments from 8-12 to 8-14 to cover more distinct QA topics. Expected: QA improves to 0.90+ for all papers, conciseness might drop slightly, avg 0.93+.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-23T00:40:19.336980891-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-23T01:22:31.843993138-07:00","closed_at":"2026-02-23T01:22:31.843993138-07:00","close_reason":"failed: 250-char limits regression. systematic_review qa 0.85→0.75, feeding qa 0.85→0.65. 200-char limits appear near-optimal. avg 0.9299→0.8926."}
{"id":"ai-pipelines-65g","title":"Establish baseline for all papers","status":"closed","priority":0,"issue_type":"task","owner":"voidfiles@gmail.com","created_at":"2026-02-22T16:08:24.655317969-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T17:36:08.053015839-07:00","closed_at":"2026-02-22T17:36:08.053015839-07:00","close_reason":"Baseline established: avg 0.9191 (qa varies 0.65-1.0, conciseness 0.81-0.97, faithfulness 0.95-1.0)"}
{"id":"ai-pipelines-8w7","title":"Experiment: Schema robustness + 280-char faithfulness fix","description":"Hypothesis: Experiments 3, 6, 7 all crashed because systematic_review data table chunks cause haiku to omit section_topic (required field). Fix: make section_topic NOT required in extraction schema (it's just informational for synthesis context). THEN apply experiment 7 improvements: 280-char main_arguments (vs 200), faithfulness self-check in template. Expected: no more crashes, no_silver_bullet qa recovers 0.85→0.95+, feeding faithfulness recovers 0.875→0.93+, avg 0.93+","status":"closed","priority":1,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T23:08:22.602607792-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T23:58:11.215954283-07:00","closed_at":"2026-02-22T23:58:11.215954283-07:00","close_reason":"failed: 'verify and remove' instruction caused over-aggressive item removal. QA dropped 0.75/0.54/0.65. Faithfulness improved (1.0) but QA destroyed. Key lesson: never add 'remove items you cannot verify' instructions."}
{"id":"ai-pipelines-95m","title":"Experiment: Two-step with 300-char compression no-merge","description":"Hypothesis: Exp4 was best (QA 1.0, 1.0, 0.80) but poor conciseness (0.71, 0.78 for no_silver_bullet and feeding). Exp5 tried to fix with 220-char limits + merge (failed - destroyed QA). Fix: Use 300-char limits WITHOUT any merge instruction. Each item compressed independently to 1 sentence at 300 chars. This should compress the verbose exp4 summary (14k chars) to ~7k while preserving the distinct content that answers QA questions. Expected: conciseness 0.86+, QA 0.95+, avg 0.94+","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T21:48:20.427000006-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T22:47:43.009472037-07:00","closed_at":"2026-02-22T22:47:43.009472037-07:00","close_reason":"failed: CRASHED + systematic_review faithfulness=0.2603 catastrophic. Two-step approach fails for large papers (331k chars) — verify step overwhelmed with 200+ extracted points, hallucinates 74% of claims. Two-step approach ruled out for mixed paper sets."}
{"id":"ai-pipelines-axs","title":"Experiment: More key_evidence items (10-14) for named entity coverage","description":"Hypothesis: From exp12 (best 0.9400). Feeding qa=0.80 (4 questions missed), faithfulness=0.9592 (4 unsupported). key_evidence is where specific named entities (tools, people) get covered. By increasing key_evidence from 8-12 to 10-14 items, we provide 2 more slots for specific facts. This should help feeding QA (more named entities covered) and potentially faithfulness (specific facts are less likely to be hallucinated than vague synthesis). Minor conciseness decrease expected.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-23T03:22:47.705258095-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-23T04:10:30.983198343-07:00","closed_at":"2026-02-23T04:10:30.983198343-07:00","close_reason":"SUCCESS: avg 0.9400→0.9549. systematic_review qa→1.0 and feeding qa→1.0. More key_evidence items (10-14) provided space for all named entities. Remaining: feeding faithfulness 0.9333 (5 unsupported claims)."}
{"id":"ai-pipelines-bq2","title":"Experiment: Named entity coverage + strict faithfulness verification","description":"Hypothesis: From exp1 baseline (avg=0.9245), two problems remain: (1) no_silver_bullet qa dropped 1.0→0.85 due to 200-char arg limits; (2) feeding faithfulness dropped 0.947→0.875. Fix: keep exp1 extraction improvements, but in synthesis: MUST include all named entities from extracted points (helps QA coverage), strict 'verify before including' faithfulness rule, and remove per-item char limit (allow natural sentence length). Keep 10-12 main_arguments count. Expected: recover no_silver_bullet qa to 0.95+, recover faithfulness across all papers.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T18:59:41.266583055-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T19:16:01.178122812-07:00","closed_at":"2026-02-22T19:16:01.178122812-07:00","close_reason":"failed: CRASHED - systematic_review chunk 36 contains XML-like tabular data causing haiku to return key_points as string instead of array. Non-deterministic prompt injection failure."}
{"id":"ai-pipelines-ca6","title":"Experiment: Two-step synthesis (draft + verify-compress)","description":"Hypothesis: Two problems in exp1: (1) 200-char limits hurt no_silver_bullet qa (1.0→0.85), (2) synthesis hallucinated for feeding (faithfulness 0.947→0.875). Fix: Add a second sonnet step 'verified_summary' that (a) takes draft synthesis + all extracted points, (b) verifies each claim traces to extracted points, (c) compresses verbose items. Step 1: no char limits, high coverage. Step 2: faithful+concise. Expected: qa back to 0.95+, faithfulness back to 0.95+, avg 0.94+.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T19:17:30.570169363-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T20:26:42.058785827-07:00","closed_at":"2026-02-22T20:26:42.058785827-07:00","close_reason":"marginal improvement avg 0.9245→0.9254. QA improved (systematic_review 0.9→1.0, no_silver_bullet 0.85→1.0) but conciseness dropped (no_silver_bullet 0.86→0.71, feeding 0.89→0.78). Need stronger compression in verify step."}
{"id":"ai-pipelines-dd8","title":"Experiment: Two-step with aggressive compression","description":"Hypothesis: Exp4 had perfect QA for systematic_review (1.0) and no_silver_bullet (1.0) thanks to draft step with no char limits. But conciseness dropped to 0.71-0.78 from 0.86-0.98. Fix: Keep two-step approach but add AGGRESSIVE compression in verify step: 'Each main_argument must be ONE sentence max 200 chars, merge items on same topic, executive_summary max 500 chars total'. Expected: maintain QA~1.0, recover conciseness to 0.85+, avg 0.94+","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T20:26:46.417585084-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T21:48:13.224969834-07:00","closed_at":"2026-02-22T21:48:13.224969834-07:00","close_reason":"failed: aggressive 220-char compression + merge instruction destroyed systematic_review QA (1.0→0.60). Avg 0.9254→0.8787 regression."}
{"id":"ai-pipelines-ef8","title":"Experiment: Tighter synthesis + better named entity extraction","description":"Hypothesis: Current main_arguments are verbose (~395 chars each × 10 items). By (1) making extraction capture specific named entities (people, products, tools, companies, concepts), and (2) forcing synthesis to write 1-sentence main_arguments (~150 chars each), we should improve conciseness for no_silver_bullet (0.81→0.90) AND qa_score for feeding_our_reading_habits (0.65→0.75+) by capturing essay-specific terminology.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T17:36:14.25035921-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T18:17:31.133483788-07:00","closed_at":"2026-02-22T18:17:31.133483788-07:00","close_reason":"improved average from 0.9191 to 0.9245 — feeding qa 0.65→0.90, but no_silver_bullet qa dropped 1.0→0.85 and faithfulness dropped"}
{"id":"ai-pipelines-ikk","title":"Experiment: Fewer items with faithfulness constraints","description":"Hypothesis: Exp1 had two problems: (1) per-item char limits caused no_silver_bullet qa to drop 1.0→0.85 (can't fit all key details in 200 chars), (2) more named entities led to faithfulness hallucinations. Fix: remove char limits, use fewer items (7-9 args, 5-7 evidence), add stronger faithfulness hedging instructions, keep improved named entity extraction. Expected: recover no_silver_bullet qa to 0.95+, recover faithfulness to 0.95+, keep feeding qa improvement.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T18:17:34.922441951-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T18:59:34.674569012-07:00","closed_at":"2026-02-22T18:59:34.674569012-07:00","close_reason":"failed: faithfulness dropped massively (systematic_review 0.9884→0.8743, 24 unsupported claims). Aggregate avg 0.9245→0.8798 regression."}
{"id":"ai-pipelines-lmx","title":"Experiment: XML injection prevention + 12-16 arguments","description":"Hypothesis: Two fixes needed: (1) XML injection prevention to stop sonnet from outputting \u003cparameter\u003e format, (2) Keep 12-16 arguments (the content was EXCELLENT in exp11 crash — 16 args with specific ρc values, k counts, n counts). Fix: add 'Output pure JSON only. Never use XML or HTML tags. All extracted points are plain text' to BOTH extraction and synthesis system_prompts. Expected: prevent crash, achieve high QA coverage with 16 detailed stats-rich arguments, avg 0.93+","status":"closed","priority":1,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-23T01:46:34.013699585-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-23T02:33:09.371786161-07:00","closed_at":"2026-02-23T02:33:09.371786161-07:00","close_reason":"improved avg 0.9299→0.9400. XML injection prevention worked (no crashes). systematic_review qa 0.85→0.95, no_silver_bullet qa back to 1.0. feeding qa slightly dropped 0.85→0.80. Faithfulness dipped slightly for all papers."}
