{"id":"ai-pipelines-65g","title":"Establish baseline for all papers","status":"closed","priority":0,"issue_type":"task","owner":"voidfiles@gmail.com","created_at":"2026-02-22T16:08:24.655317969-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T17:36:08.053015839-07:00","closed_at":"2026-02-22T17:36:08.053015839-07:00","close_reason":"Baseline established: avg 0.9191 (qa varies 0.65-1.0, conciseness 0.81-0.97, faithfulness 0.95-1.0)"}
{"id":"ai-pipelines-ef8","title":"Experiment: Tighter synthesis + better named entity extraction","description":"Hypothesis: Current main_arguments are verbose (~395 chars each × 10 items). By (1) making extraction capture specific named entities (people, products, tools, companies, concepts), and (2) forcing synthesis to write 1-sentence main_arguments (~150 chars each), we should improve conciseness for no_silver_bullet (0.81→0.90) AND qa_score for feeding_our_reading_habits (0.65→0.75+) by capturing essay-specific terminology.","status":"closed","priority":2,"issue_type":"feature","owner":"voidfiles@gmail.com","created_at":"2026-02-22T17:36:14.25035921-07:00","created_by":"Alex Kessinger","updated_at":"2026-02-22T18:17:31.133483788-07:00","closed_at":"2026-02-22T18:17:31.133483788-07:00","close_reason":"improved average from 0.9191 to 0.9245 — feeding qa 0.65→0.90, but no_silver_bullet qa dropped 1.0→0.85 and faithfulness dropped"}
