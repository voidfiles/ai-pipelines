# EXPERIMENT: Named entity coverage + strict faithfulness verification
# DATE: 2026-02-22
# HYPOTHESIS: Keep exp1 extraction, remove 200-char limits, add "verify before including" faithfulness
# RESULT: CRASHED — systematic_review chunk 36 has XML-like tabular content that
#   caused haiku to return key_points as a string instead of array (prompt injection).
#   ValidationError: key_points 'is not of type array'. Non-deterministic failure.
# FAILURE REASON: Same extraction prompt as exp1 but crashed this time on chunk 36 of
#   systematic_review paper. This chunk contains tabular/XML-like data. Only changed synthesis.
# ---
input:
  type: object
  properties:
    paper_path:
      type: string
      description: Path to a markdown file containing an academic paper
  required:
    - paper_path

steps:
  # ── Read the paper ───────────────────────────────────────────────
  - kind: read_file
    name: paper
    arguments: input.paper_path

  # ── Chunk it into manageable pieces ──────────────────────────────
  - kind: chunk
    name: chunked
    arguments: paper
    chunk_size: 6000
    overlap: 400

  # ── Summarize each chunk ─────────────────────────────────────────
  - kind: for_each
    name: chunk_summaries
    arguments: chunked.chunks
    steps:
      - kind: prompt
        name: summary
        arguments: '{"text": item.text, "chunk_index": item.index, "total_chunks": $count(chunked.chunks)}'
        model: haiku
        system_prompt: |
          You are an expert academic paper analyst extracting structured information
          from any type of written work — academic papers, essays, blog posts, books,
          or reports. Your job is to capture ALL of the following from each section:

          1. NAMED ENTITIES: Every person (full name with suffix/title), organization,
             company, product, tool, or technology mentioned — e.g. "Frederick P. Brooks Jr.",
             "Google Reader", "Feedly", "Chris Wetherell", "The Wire".
          2. KEY CLAIMS: The specific arguments, findings, definitions, and conclusions
             made in this section. Include numerical data, percentages, and rankings.
          3. TECHNICAL CONCEPTS: Any named framework, methodology, effect, or concept
             introduced or used — e.g. "Kuleshov Effect", "chain of density", "NLI".
          4. COMPARISONS AND CONTRASTS: Any explicit comparisons between approaches,
             tools, or ideas.

          Be faithful to the source. Extract exact phrasing when the author uses
          specific language (e.g. "holds more promise than any other technical fad").
          If a section contains mostly navigation or references with little substance,
          note that briefly.
        template: |
          This is chunk {{ args.chunk_index }} of {{ args.total_chunks }} from a written work.

          --- BEGIN CHUNK ---
          {{ args.text }}
          --- END CHUNK ---

          Extract all key information from this section. Capture every named person,
          organization, product, and tool explicitly. For each point, classify its type.
        output:
          type: object
          properties:
            key_points:
              type: array
              items:
                type: object
                properties:
                  point:
                    type: string
                    description: The key point, claim, entity, or concept — be specific and include names
                  category:
                    type: string
                    description: "Type: argument | evidence | definition | conclusion | named_entity | comparison"
                required:
                  - point
                  - category
            section_topic:
              type: string
              description: Brief description of what this section covers
          required:
            - key_points
            - section_topic

  # ── Flatten all key points ───────────────────────────────────────
  - kind: transform
    name: all_points
    arguments: chunk_summaries.key_points

  # ── Synthesize into a final summary ──────────────────────────────
  - kind: prompt
    name: final_summary
    arguments: '{"points": $reduce(all_points, $append), "section_topics": chunk_summaries.section_topic}'
    model: sonnet
    system_prompt: |
      You are an expert at synthesizing written works into faithful, concise, and
      informationally dense structured summaries.

      FAITHFULNESS RULES (NON-NEGOTIABLE — violation ruins the score):
      - BEFORE writing any claim, verify it appears in the extracted points list below.
        If you cannot find explicit support for a claim, OMIT IT entirely.
      - Use the author's exact hedging language ("could reduce", "may help", "suggests"):
        never upgrade to absolutes ("eliminates", "solves", "proves")
      - Do not misattribute: if the source says "X applies to Y", do not write "X applies to Z"
      - Include the author's full name and affiliation exactly as stated

      COVERAGE RULES (for QA score):
      - Include ALL named persons (full names with Jr./Sr./Dr.), organizations, products,
        tools, and named concepts that appear in the extracted points
      - Include ALL specific comparisons, rankings, quantitative data, and distinctive phrases
      - Cover every major section of the work

      CONCISENESS RULES:
      - Write 10-12 main_arguments: 1-2 tight sentences each, covering all major points
      - Write 6-10 key_evidence items: 1-2 tight sentences, naming specific entities/data
      - Write 5-8 conclusions: 1 tight sentence each
      - Executive summary: 3-4 sentences covering the whole work
      - Pack maximum information. Omit filler. Use precise nouns over vague descriptions.
    template: |
      The following key points were extracted from a written work:

      Sections covered: {{ args.section_topics | join(", ") }}

      All extracted points:
      {% for point in args.points %}
      - [{{ point.category | upper }}] {{ point.point }}
      {% endfor %}

      Synthesize these into a structured summary following ALL rules from the system prompt.

      CRITICAL: For each claim you write, check that it appears in the extracted points above.
      Name all significant persons (full names), organizations, products, and tools.
      Cover all major topics from all sections.
    output:
      type: object
      properties:
        executive_summary:
          type: string
          description: 3-4 sentence overview (max 600 chars)
        core_thesis:
          type: string
          description: The central argument or claim in one sentence
        main_arguments:
          type: array
          items:
            type: string
          description: 8-12 one-sentence arguments (max 200 chars each)
        key_evidence:
          type: array
          items:
            type: string
          description: 6-10 one-sentence evidence items with specific names and data
        conclusions:
          type: array
          items:
            type: string
          description: 5-8 one-sentence conclusions or recommendations
      required:
        - executive_summary
        - core_thesis
        - main_arguments
        - key_evidence
        - conclusions
